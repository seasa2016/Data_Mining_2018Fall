{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = {}\n",
    "with open('./data/glove.840B.300d/glove.840B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        word = ' '.join(line[:-300])\n",
    "        temp = []\n",
    "        for num in line[-300:]:\n",
    "            temp.append(float(num))\n",
    "        emb[word] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'id2w':['pad'],'w2id':{'pad':0}}\n",
    "vocab = [[0]*300]\n",
    "for word in emb:\n",
    "    mapping['id2w'].append(word)\n",
    "    mapping['w2id'][word] = len(mapping['w2id'])\n",
    "    vocab.append(emb[word])\n",
    "vocab = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, '.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['w2id']['.'],mapping['id2w'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class itemDataset(Dataset):\n",
    "    def __init__(self, file_name,mapping,transform=None):\n",
    "        self.data = {0:[],1:[]}\n",
    "        self.mapping = mapping\n",
    "        \n",
    "        self.build_data(file_name)\n",
    "        self.transform = transform\n",
    "    def build_data(self,file_name):\n",
    "        data = pd.read_csv(file_name)\n",
    "        line = data['question_text'].tolist()\n",
    "        target = data['target'].tolist()\n",
    "        \n",
    "        def token(line):\n",
    "            line = line.lower()\n",
    "            line = nltk.word_tokenize(line)\n",
    "            temp = []\n",
    "            for w in line:\n",
    "                try:\n",
    "                    temp.append(self.mapping['w2id'][w])\n",
    "                except:\n",
    "                    temp.append(0)\n",
    "            return temp\n",
    "            \n",
    "        for data,label in zip(line,target):\n",
    "            self.data[label].append( token(data).copy() )\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data[1])\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        \n",
    "        sample['pos'] = self.data[1][ idx ]\n",
    "        sample['pos_len'] = len(sample['pos'])\n",
    "        \n",
    "        sample['neg'] = self.data[0][ np.random.randint(low=0,high=len(self.data[0])) ]\n",
    "        sample['neg_len'] = len(sample['neg'])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self,sample):\n",
    "        for name in sample:\n",
    "            sample[name] = torch.tensor(sample[name],dtype=torch.long)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    parsing the data list into batch tensor\n",
    "    ['pos','neg','pos_len','neg_len']\n",
    "    \"\"\"\n",
    "    output = dict()\n",
    "\n",
    "    for name in ['pos_len','neg_len']:\n",
    "        temp = [ _[name] for _ in data]\t \n",
    "        output[name] = torch.stack(temp, dim=0) \n",
    "\n",
    "        \n",
    "    #deal with source and target\n",
    "    for name in ['pos','neg']:\n",
    "        length = output['{0}_len'.format(name)]\n",
    "        l = length.max().item()\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if(l-length[i].item()>0):\n",
    "                data[i][name] =  torch.cat([data[i][name],torch.zeros(l-length[i].item(),dtype=torch.long)],dim=-1)\n",
    "\n",
    "        temp = [ _[name] for _ in data]\n",
    "        output[name] = torch.stack(temp, dim=0).long()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = itemDataset( file_name='./data/train.csv',mapping=mapping,transform=transforms.Compose([ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2,shuffle=True, num_workers=16,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40405"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DECODER(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(DECODER,self).__init__()\n",
    "        self.hidden_size = args.hidden_dim\n",
    "        \n",
    "        self.fnn1 = nn.Linear(2*self.hidden_size,self.hidden_size)\n",
    "        self.fnn2 = nn.Linear(self.hidden_size,1)\n",
    "    def forward(self,x):\n",
    "        out = self.fnn1(x)\n",
    "        out = f.relu(out)\n",
    "        out = self.fnn2(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANK(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(RANK,self).__init__()\n",
    "        self.hidden_size = args.hidden_dim\n",
    "        \n",
    "        self.fnn1 = nn.Linear(4*self.hidden_size,self.hidden_size)\n",
    "        self.fnn2 = nn.Linear(self.hidden_size,1)\n",
    "    def forward(self,x,y):\n",
    "        out = torch.cat([x,y],dim=-1)\n",
    "        \n",
    "        out = self.fnn1(out)\n",
    "        out = f.relu(out)\n",
    "        out = self.fnn2(out)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIRNN_end(nn.Module):\n",
    "    def __init__(self,args,vocab):\n",
    "        super(BIRNN_end,self).__init__()\n",
    "        self.input_size = args.input_size\n",
    "        self.hidden_size = args.hidden_dim\n",
    "        self.num_layer = args.num_layer\n",
    "        self.batch_first = args.batch_first\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "\n",
    "        self.word_embedding = nn.Embedding(args.input_size,args.word_dim)\n",
    "        self.word_embedding.weight = nn.Parameter(torch.tensor(vocab,dtype=torch.float32))\n",
    "        self.word_embedding.weight.required_grad = False\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=args.word_dim,\n",
    "            hidden_size=args.hidden_dim,\n",
    "            num_layers=args.num_layer,\n",
    "            batch_first=args.batch_first,\n",
    "            dropout=args.dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "    def forward(self,query,query_len):\n",
    "        def pack(seq,seq_length):\n",
    "            sorted_seq_lengths, indices = torch.sort(seq_length, descending=True)\n",
    "            _, desorted_indices = torch.sort(indices, descending=False)\n",
    "\n",
    "            if self.batch_first:\n",
    "                seq = seq[indices]\n",
    "            else:\n",
    "                seq = seq[:, indices]\n",
    "            packed_inputs = nn.utils.rnn.pack_padded_sequence(seq,\n",
    "                                                            sorted_seq_lengths.cpu().numpy(),\n",
    "                                                            batch_first=self.batch_first)\n",
    "\n",
    "            return packed_inputs,desorted_indices\n",
    "\n",
    "        def unpack(res, state,desorted_indices):\n",
    "            padded_res,_ = nn.utils.rnn.pad_packed_sequence(res, batch_first=self.batch_first)\n",
    "\n",
    "            state = [state[i][:,desorted_indices] for i in range(len(state)) ] \n",
    "\n",
    "            if(self.batch_first):\n",
    "                desorted_res = padded_res[desorted_indices]\n",
    "            else:\n",
    "                desorted_res = padded_res[:, desorted_indices]\n",
    "\n",
    "            return desorted_res,state\n",
    "\n",
    "        def feat_extract(query_output,query_length):\n",
    "            \"\"\"\n",
    "            answer_output: batch*sentence*feat_len\n",
    "            query_output:  batch*sentence*feat_len\n",
    "\n",
    "\n",
    "            for simple rnn, we just take the output from \n",
    "            \"\"\"\n",
    "            if( self.batch_first == False ):\n",
    "                query_output = query_output.transpose(0,1) \n",
    "\n",
    "            query_output = [torch.cat([ query_output[i][ query_length[i]-1 ][:self.hidden_size] , \n",
    "                                        query_output[i][0][self.hidden_size:]] , dim=-1 ) for i in range(query_length.shape[0])]\n",
    "            query_output = torch.stack(query_output,dim=0)\n",
    "\n",
    "            return query_output\n",
    "\n",
    "        #first check for the mask ans the embedding\n",
    "\n",
    "        mask =  query.eq(0)\n",
    "\n",
    "        query_emb = self.word_embedding(query)\n",
    "\n",
    "        #query part\n",
    "        packed_inputs,desorted_indices = pack(query_emb,query_len)\n",
    "        res, state = self.rnn(packed_inputs)\n",
    "        query_res,_ = unpack(res, state,desorted_indices)\n",
    "\n",
    "        #extract the representation of the sentence\n",
    "        query_result = feat_extract(query_res,query_len.int())\n",
    "        \n",
    "        return query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temp:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = temp()\n",
    "\n",
    "args.input_size = len(emb)+1\n",
    "args.hidden_dim = 300\n",
    "args.word_dim = 300\n",
    "args.num_layer = 2\n",
    "args.batch_first = True\n",
    "args.dropout = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BIRNN_end(args,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = DECODER(args)\n",
    "rank = RANK(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.gpu = -1\n",
    "args.learning_rate = 0.001\n",
    "args.epoch = 10\n",
    "args.print_freq = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data,device):\n",
    "    for name in data:\n",
    "        data[name] = data[name].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check device\n",
      "the device is in cpu\n",
      "BIRNN_end(\n",
      "  (word_embedding): Embedding(2195896, 300)\n",
      "  (rnn): LSTM(300, 300, num_layers=2, batch_first=True, bidirectional=True)\n",
      ")\n",
      "start training\n",
      "0\n",
      "0\n",
      "**********\n",
      " training loss(class):1.5795660142836012e-05 (rank):5.7967664168444826e-05 (cate):2  acc:80810/2 40405/0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"check device\")\n",
    "if(torch.cuda.is_available() and args.gpu>=0):\n",
    "    device = torch.device('cuda')\n",
    "    print('the device is in cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('the device is in cpu')\n",
    "\n",
    "model = model.to(device=device)\n",
    "decoder = decoder.to(device=device)\n",
    "rank = rank.to(device=device)\n",
    "print(model)\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "loss_best = 100000000\n",
    "print(\"start training\")\n",
    "for now in range(args.epoch):\n",
    "    print(now)\n",
    "\n",
    "    Loss = {'class':0,'rank':0,'cate':0}\n",
    "    Count = {'class':0,'rank':0,'cate':0}\n",
    "    temp_Loss = {'class':0,'rank':0,'cate':0}\n",
    "    temp_Count = {'class':0,'rank':0,'cate':0}\n",
    "\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    for i,data in enumerate(dataloader):\n",
    "        print(i)\n",
    "        convert(data,device)\n",
    "\n",
    "        #deal with the classfication part\n",
    "        query_left = model(data['pos'],data['pos_len'])\n",
    "        out_left = decoder(query_left)\n",
    "        \n",
    "        pred = (out_left.sigmoid()>0.5).int()\n",
    "        temp_Count['class'] += ( pred.eq(1) ).sum()\n",
    "        Count['class'] += ( pred.eq(1) ).sum()\n",
    "\n",
    "        loss = criterion(out_left,torch.ones(out_left.shape)) \n",
    "        total_loss = loss\n",
    "        temp_Loss['rank'] = loss.detach().cpu().item()\n",
    "        Loss['rank'] += loss.detach().cpu().item()\n",
    "\n",
    "        query_right = model(data['neg'],data['neg_len'])\n",
    "        out_right = decoder(query_right)\n",
    "        \n",
    "        pred = (out_right.sigmoid()<0.5).int()\n",
    "        temp_Count['class'] += ( pred.eq(0) ).sum()\n",
    "        Count['class'] += ( pred.eq(0) ).sum()\n",
    "\n",
    "        loss = criterion(out_right,torch.zeros(out_right.shape)) \n",
    "        total_loss += loss\n",
    "        temp_Loss['class'] += loss.detach().cpu().item()\n",
    "        Loss['class'] += loss.detach().cpu().item()\n",
    "\n",
    "        #deal with the ranking part\n",
    "        \n",
    "        if(i%2):\n",
    "            out = rank(query_left,query_right)\n",
    "            label = torch.ones(out.shape)\n",
    "        else:\n",
    "            out = rank(query_right,query_left)\n",
    "            label = torch.zeros(out.shape)\n",
    "            \n",
    "        pred = ((out.sigmoid()>0.5).int() == label.int() )\n",
    "        temp_Count['rank'] +=  pred.sum()\n",
    "        Count['rank'] +=  pred.sum()\n",
    "\n",
    "        loss = criterion(out,label) \n",
    "        total_loss += loss\n",
    "        temp_Loss['rank'] = loss.detach().cpu().item()\n",
    "        Loss['rank'] += loss.detach().cpu().item()\n",
    "\n",
    "        #temp_Loss.backward(retain_graph=True)\n",
    "        total_loss.backward()\n",
    "\n",
    "        if(i%4==0):\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            break\n",
    "\n",
    "        if(i%160==0):\n",
    "            #print('out',out_right.sigmoid().view(-1))\n",
    "            #print('label',data['right_type'].view(-1))\n",
    "            print(i,' training loss(class):{0} (rank):{1} (cate):{2}  acc:{3}/{4} {5}/{6} {7}/{8}'.format(\n",
    "                temp_Loss['class'],temp_Loss['rank'],temp_Loss['cate'],temp_Count['class'],args.batch_size*320,temp_Count['rank'],args.batch_size*160,args.batch_size*160))\n",
    "\n",
    "            temp_Loss = {'class':0,'rank':0,'cate':0}\n",
    "            temp_Count = {'class':0,'rank':0,'cate':0}\n",
    "    if(now%args.print_freq==0):\n",
    "        print('*'*10)\n",
    "        print(' training loss(class):{0} (rank):{1} (cate):{2}  acc:{3}/{4} {5}/{6}'.format(Loss['class']/len(dataloader)/2,Loss['rank']/len(dataloader),Count['class'],len(dataloader)*2,Count['rank'],len(dataloader),Count['cate'],len(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training loss(class):0.0 (rank):2.8635351806270533e-05 (cate):2  acc:80810/2 40405/0\n"
     ]
    }
   ],
   "source": [
    "print(' training loss(class):{0} (rank):{1} (cate):{2}  acc:{3}/{4} {5}/{6}'.format(Loss['class']/len(dataloader)/2,Loss['rank']/len(dataloader),Count['class'],len(dataloader)*2,Count['rank'],len(dataloader),Count['cate'],len(dataloader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
